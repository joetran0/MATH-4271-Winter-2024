\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{amsfonts, amssymb, amsmath, amsthm, booktabs, hyperref, pgfplots, tikz, xcolor}

\theoremstyle{definition}\newtheorem{definition}{Definition}
\theoremstyle{definition}\newtheorem{notation}{Notation}
\theoremstyle{definition}\newtheorem{example}{Example}
\theoremstyle{theorem}\newtheorem{theorem}{Theorem}
\theoremstyle{theorem}\newtheorem{corollary}{Corollary}
\theoremstyle{theorem}\newtheorem{proposition}{Proposition}
\theoremstyle{theorem}\newtheorem{lemma}{Lemma}
\theoremstyle{theorem}\newtheorem{question}{Question}
\theoremstyle{remark}\newtheorem{remark}{Remark}

\newcommand{\K}{\mathbb{K}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\F}{\mathbb{F}}
\renewcommand{\SS}{\mathcal{S}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\teq}{\trianglelefteq}
\DeclareMathOperator{\Char}{char}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\Span}{span}

\everymath{\displaystyle}

\setlength{\parskip}{5pt}

\begin{document}

\noindent \textbf{MATH 4271 Dynamical Systems} \hfill \textbf{Lecture 3} \\
\textsc{Lecture} \hfill \textsc{Joe Tran}

Recall in the previous lecture we have started to generalize subcase 2 to $n \times n$. We define and generalized eigenvectors.

\begin{definition}
    If $\lambda$ is an eigenvalue of $A$ with multiplicity $m \leq n$, then any nonzero solution $\vec{v}$ of $(A - \lambda I_n)^k \vec{v} = \vec{0}$ for $k = 1, 2,..., m$, is called a generalized eigenvector of $A$.
\end{definition}

In particular, for $2 \times 2$, if $\vec{v}_2$ is a generalized eigenvector, it can be obtained as
\begin{equation*}
    (A - \lambda I_2) \vec{v}_2 = \vec{v}_1
\end{equation*}
and so
\begin{equation*}
    A\vec{v}_2 = \vec{v}_1 + \lambda I_2\vec{v}_2
\end{equation*}
The general solution is given by
\begin{equation*}
    \vec{x}(t) = \sum_{j = 1}^{m} c_j \vec{x}_j(t)
\end{equation*}
where if $j = 1$, $\vec{x}_1(t) = \vec{v}_1e^{\lambda t}$, if $j = 2$, then $\vec{v}_1te^{\lambda t} + \vec{v}_2e^{\lambda t}$, and for when $j = 3$, then
\begin{align*}
    \vec{x}_3(t) = \frac{1}{2!}t^2\vec{x}_1(t) + t\vec{v}_2e^{\lambda t} + \vec{v}_3e^{\lambda t}
\end{align*}
In general,
\begin{equation*}
    \vec{x}_n(t) = \frac{1}{(n - 1)!}t^{n - 1}\vec{x}_1(t) + \frac{1}{(n - 2)!}t^{n - 2}\vec{x}_2(t) + \cdots + \vec{v}_{n - 1}te^{\lambda t} + \vec{v}_n e^{\lambda t}
\end{equation*}
 
\underline{Case 3:} If $A$ has $k$ pairs of complex conjugate eigenvalues, i.e. $\lambda_j = a_j + ib_j$, where $j = 1, 2,... k$. Assume that $\vec{v}_j = \vec{\alpha}_j + i\vec{\beta}_j$ be the corresponding eigenvectors. Then the solution of $\frac{d\vec{x}}{dt} = A\vec{x}$ is
\begin{equation*}
    \vec{x}(t) = \sum_{j = 1}^{k}\left(c_j\vec{u}_j + d_j\vec{v}_j\right)
\end{equation*}
where $\vec{u}_j = (\vec{\alpha}_j\cos(b_jt) - \vec{\beta}_j\sin(b_jt))e^{a_jt}$ and $\vec{v}_j = (\vec{\alpha}_j\cos(b_jt) + \vec{\beta}_j\sin(b_jt))e^{a_jt}$.

\begin{example}
    Solve the system $\frac{dx_1}{dt} = 3x_1 - 4x_2$, $\frac{dx_2}{dt} = x_1 - x_2$.
\end{example}

Recall that to find the eigenvalues, we solve $\det(A - \lambda I_2) = 0$. Indeed,
\begin{equation*}
    \begin{bmatrix} \frac{dx_1}{dt} \\ \frac{dx_2}{dt} \end{bmatrix} = \begin{bmatrix} 3 & -4 \\ 1 & -1 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}
\end{equation*}
where $A = \begin{bmatrix} 3 & -4 \\ 1 & -1 \end{bmatrix}$. Finding the eigenvalues gives
\begin{align*}
    \chi_A(\lambda) &= \det(A - \lambda I_2) = \begin{vmatrix} 3 - \lambda & -4 \\ 1 & -1 - \lambda \end{vmatrix} \\
    &= (3 - \lambda)(-1 - \lambda) + 4 \\
    &= \lambda^2 - 2\lambda + 1 \\
    &= (\lambda - 1)^2 = 0
\end{align*}
We have that $\lambda = 1$. Next, we find the eigenvector corresponding to $\lambda = 1$. Indeed,
\begin{align*}
    \E_A(1) &= \ker\left\{\begin{bmatrix} 3 - 1 & -4 \\ 1 & -1 - 1 \end{bmatrix}\right\} \\
    &= \ker\left\{\begin{bmatrix} 2 & -4 \\ 1 & -2 \end{bmatrix}\right\} \\
    &= \ker\left\{\begin{bmatrix} 1 & -2 \\ 1 & -2 \end{bmatrix}\right\} \\
    &= \ker\left\{\begin{bmatrix} 1 & -2 \\ 0 & 0 \end{bmatrix}\right\} \\
    &= \left\{\begin{bmatrix} 2s \\ s \end{bmatrix} : s \in \R\right\} \\
    &= \Span\left\{\begin{bmatrix} 2 \\ 1 \end{bmatrix}\right\}
\end{align*}
Therefore, $\vec{v}_1 = \begin{bmatrix} 2 \\ 1 \end{bmatrix}$ is an eigenvector of the eigenspace $\E_A(1)$. Then using the generalized eigenvector formula, we have $\vec{v}_1$, so we find $\vec{v}_2$ by $\vec{v}_2 = (A - \lambda I_2)\vec{v}_1$. Indeed,
\begin{align*}
    \begin{bmatrix} 
        2 & -4 \\
        1 & -2
    \end{bmatrix} \begin{bmatrix} v_{21} \\ v_{22} \end{bmatrix} = \begin{bmatrix} 2 \\ 1 \end{bmatrix}
\end{align*}
and so solving the system of equations above, we obtain
\begin{equation*}
    \vec{v}_2 = \begin{bmatrix} 3 \\ 1 \end{bmatrix}
\end{equation*}
Therefore, the general solution of the system is
\begin{align*}
    \vec{x}(t) &= c_1\vec{x}_1(t) + c_2\vec{x}_2(t) \\
    &= c_1\vec{v}_1e^{t} + c_2(t\vec{x}_1(t) + \vec{v}_2e^{\lambda t}) \\
    &= c_1\begin{bmatrix} 2 \\ 1 \end{bmatrix} e^t  + c_2\left(t\begin{bmatrix} 2 \\ 1 \end{bmatrix} e^t + \begin{bmatrix} 3 \\ 1 \end{bmatrix} e^t\right)
\end{align*}

\begin{example}
    Solve the system given by
    \begin{equation*}
        \frac{d\vec{x}}{dt} = \begin{bmatrix} 1 & 1 \\ -1 & 1 \end{bmatrix} \vec{x}
    \end{equation*}
    Then $A = \begin{bmatrix} 1 & 1 \\ -1 & 1 \end{bmatrix}$, and so finding the eigenvalues we have
    \begin{align*}
        \chi_A(\lambda) &= \det(A - \lambda I_2) \\
        &= \begin{vmatrix} 1 - \lambda & 1 \\ -1 & 1 - \lambda \end{vmatrix} \\
        &= (1 - \lambda)^2 + 1 \\
        &= (\lambda - 1)^2 - i^2 \\
        &= (\lambda - 1 + i)(\lambda - 1 - i) = 0
    \end{align*}
    So we have eigenvalues $\lambda = 1 - i$ and $\lambda = 1 + i$. Now we find the eigenspaces of $\lambda = 1 - i$ and $\lambda = 1 + i$. Indeed, for $\lambda = 1 - i$,
    \begin{align*}
        \E_A(1 - i) &= \ker\left\{\begin{bmatrix} 1 - (1 - i) & 1 \\ -1 & 1 - (1 - i) \end{bmatrix}\right\} \\
        &= \ker\left\{\begin{bmatrix} i & 1 \\ -1 & i \end{bmatrix}\right\} \\
        &= \ker\left\{\begin{bmatrix} 1 & -i \\ -1 & i \end{bmatrix}\right\} \\
        &= \ker\left\{\begin{bmatrix} 1 & -i \\ 0 & 0 \end{bmatrix}\right\} \\
        &= \left\{\begin{bmatrix} is \\ s \end{bmatrix} : s \in \R\right\} \\
        &= \Span\left\{\begin{bmatrix} i \\ 1 \end{bmatrix}\right\}
    \end{align*}
    and similarly, one can find that $\E_A(1 + i) = \Span\left\{\begin{bmatrix} -i \\ 1 \end{bmatrix}\right\}$. So we may take two eigenvectors $\vec{v}_1 = \begin{bmatrix} i \\ 1 \end{bmatrix} \in \E_A(1 - i)$ and $\vec{v}_2 = \begin{bmatrix} -i \\ 1 \end{bmatrix} \in \E_A(1 + i)$. Then note that
    \begin{align*}
        \vec{v}_1 &= \begin{bmatrix} 0 \\ 1 \end{bmatrix} + i\begin{bmatrix} 1 \\ 0 \end{bmatrix} = \vec{\alpha}_1 + i\vec{\alpha}_2 \\ 
        \vec{v}_2 &= \begin{bmatrix} 0 \\ 1 \end{bmatrix} + i\begin{bmatrix} -1 \\ 0 \end{bmatrix} = \vec{\alpha}_1 - i\vec{\alpha}_2
    \end{align*}
    and so
    \begin{align*}
        \vec{u}_1 &= e^{at}\left(\vec{\alpha}_1\cos(bt) - \vec{\alpha}_2\sin(bt)\right) = e^t\left(\begin{bmatrix} 0 \\ 1 \end{bmatrix}\cos(t) - \begin{bmatrix} 1 \\ 0 \end{bmatrix}\sin(t)\right) \\
        \vec{u}_2 &= e^{at}\left(\vec{\alpha}_1\cos(bt) + \vec{\alpha}_2\sin(bt)\right) = e^t\left(\begin{bmatrix} 0 \\ 1 \end{bmatrix}\cos(t) + \begin{bmatrix} 1 \\ 0 \end{bmatrix}\sin(t)\right)
    \end{align*}
    Therefore,
    \begin{align*}
        \vec{x}(t) = c_1\vec{u}_1 + d_1\vec{u}_2
    \end{align*}
\end{example}

\begin{definition}
    Any set $\{\vec{x}_1(t),..., \vec{x}_n(t)\}$ of solution (1) is said to be a Fundamental set of solution of (1) if
    \begin{enumerate}
        \item The set is linearly independent
        \item For any $\vec{x}(t) \in \R^n$ of (1) can be written in the form
        \begin{equation*}
            \vec{x}(t) = c_1\vec{x}_1(t) + c_2\vec{x}(t) + \cdots + c_n\vec{x}_n(t)
        \end{equation*}
    \end{enumerate}
\end{definition}
The matrix
\begin{equation*}
    \phi(t) = \begin{bmatrix}
        \vec{x}_1(t) & \vec{x}_2(t) & \vdots & \vec{x}_n(t)
    \end{bmatrix}
\end{equation*}
is called the Fundamental Matrix of (1), which is an $n \times n$ matrix.

\begin{remark}
    Note that $\phi(t)$ is an invertible matrix, since $\vec{x}_1(t),..., \vec{x}_n(t)$ are linearly independent vectors.
\end{remark}

Let $\vec{x}_1(t)$, $\vec{x}_2(t)$,..., $\vec{x}_n(t)$ is a linearly independent solution. The general solution of (1) is
\begin{align*}
    \vec{x}(t) &= c_1\vec{x}_1(t) + c_2\vec{x}_2(t) + \cdots + c_n\vec{x}_n(t) \\
    &= \begin{bmatrix} \vec{x}_1(t) & \vec{x}_2(t) & \cdots & \vec{x}_n(t) \end{bmatrix} \begin{bmatrix} c_1 \\ c_2 \\ \vdots \\ c_n \end{bmatrix} \\
    &= \phi(t)\vec{c}
\end{align*}
where $\vec{c}$ is an arbitrary constant vector. In particular, suppose we are given an initial condition that $\vec{x}(0) = \vec{x}_0$. Then $\vec{x}_0 = \phi(0)\vec{c}$, and so $\phi^{-1}(0)\vec{x}_0 = \vec{c}$. Thus, the solution of the initial value problem is
\begin{equation*}
    \vec{x}(t) = \phi(t)\phi^{-1}(0)\vec{x}_0 \tag{*}
\end{equation*}


\end{document}